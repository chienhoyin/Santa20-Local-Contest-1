{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entitled-policy",
   "metadata": {},
   "source": [
    "### CAVEATS\n",
    "1. need to remove game with \"statuses\" != [\"DONE\", \"DONE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import read_json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deluxe-balloon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10256462.json\r\n",
      "10256880.json\r\n",
      "10257326.json\r\n",
      "10257684.json\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../dataset/topagent_dataset/episode | head -n 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acting-madonna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict,\n",
       " dict_keys(['configuration', 'description', 'id', 'info', 'name', 'rewards', 'schema_version', 'specification', 'statuses', 'steps', 'title', 'version']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../dataset/topagent_dataset/episode/10257684.json'\n",
    "game = read_json(path)\n",
    "type(game), game.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effective-japan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[677, 654]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "balanced-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([step[0]['action'] for step in game['steps']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "mediterranean-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_game(data):\n",
    "    if data['statuses'] == ['DONE', 'DONE']:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mature-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_training(data, n_machines = 100):\n",
    "    \"\"\"Records training data from each machine, each agent, each round\n",
    "    \n",
    "    Generates a training dataset to support prediction of the current\n",
    "    payout ratio for a given machine.\n",
    "    \n",
    "    Args:\n",
    "       result ([[dict]]) - output from all rounds provided as output of \n",
    "                           env.run([agent1, agent2])\n",
    "       n_machines (int) - number of machines\n",
    "                           \n",
    "    Returns:\n",
    "       training_data (pd.DataFrame) - training data, including:\n",
    "           \"round_num\"      : round number\n",
    "           \"machine_id\"     : machine data applies to\n",
    "           \"agent_id\"       : player data applies to (0 or 1)\n",
    "           \"n_pulls_self\"   : number of pulls on this machine so far by agent_id\n",
    "           \"n_success_self\" : number of rewards from this machine by agent_id\n",
    "           \"n_pulls_opp\"    : number of pulls on this machine by the other player\n",
    "           \"payout\"         : actual payout ratio for this machine\n",
    "    \n",
    "    \"\"\"\n",
    "    result = data['steps']\n",
    "    \n",
    "    # Initialize machine and agent states\n",
    "    machine_state = [{'n_pulls_0': 0, 'n_success_0': 0,\n",
    "                      'n_pulls_1': 0, 'n_success_1': 0,\n",
    "                      'payout': None}\n",
    "                     for ii in range(n_machines)]\n",
    "    agent_state = {'reward_0': 0, 'reward_1': 0, 'last_reward_0': 0,\n",
    "                   'last_reward_1': 0}\n",
    "\n",
    "    # Initialize training dataframe\n",
    "    # - In the first round, store records for all n_machines\n",
    "    # - In subsequent rounds, just store the two machines that updated\n",
    "    training_data = pd.DataFrame(\n",
    "            index=range(n_machines + 4 * (len(result) - 1)),\n",
    "            columns=['round_num', 'machine_id', 'agent_id',\n",
    "                     'n_pulls_self', 'n_success_self',\n",
    "                     'n_pulls_opp', 'payout'])\n",
    "    \n",
    "    # Log training data from each round\n",
    "    for round_num, res in enumerate(result):\n",
    "        # Get current threshold values\n",
    "        thresholds = res[0]['observation']['thresholds']\n",
    "\n",
    "        # Update agent state\n",
    "        for agent_ii in range(2):\n",
    "            agent_state['last_reward_%i' % agent_ii] = (\n",
    "                res[agent_ii]['reward']\n",
    "                - agent_state['reward_%i' % agent_ii])\n",
    "            agent_state['reward_%i' % agent_ii] = res[agent_ii]['reward']        \n",
    "\n",
    "        # Update most recent machine state\n",
    "        if res[0]['observation']['lastActions']:\n",
    "            for agent_ii, r_obs in enumerate(res):\n",
    "                action = r_obs['action']\n",
    "                machine_state[action]['n_pulls_%i' % agent_ii] += 1\n",
    "                machine_state[action]['n_success_%i' % agent_ii] += \\\n",
    "                    agent_state['last_reward_%i' % agent_ii]\n",
    "                machine_state[action]['payout'] = thresholds[action]\n",
    "        else:\n",
    "            # Initialize machine states\n",
    "            for mach_ii in range(n_machines):\n",
    "                machine_state[mach_ii]['payout'] = thresholds[mach_ii]\n",
    "            \n",
    "        # Record training records\n",
    "        # -- Each record includes:\n",
    "        #       round_num, n_pulls_self, n_success_self, n_pulls_opp\n",
    "        if res[0]['observation']['lastActions']:\n",
    "            # Add results for most recent moves\n",
    "            for agent_ii, r_obs in enumerate(res):\n",
    "                action = r_obs['action']\n",
    "\n",
    "                # Add row for agent who acted\n",
    "                row_ii = n_machines + 4 * (round_num - 1) + 2 * agent_ii \n",
    "                training_data.at[row_ii, 'round_num'] = round_num\n",
    "                training_data.at[row_ii, 'machine_id'] = action\n",
    "                training_data.at[row_ii, 'agent_id'] = agent_ii\n",
    "                training_data.at[row_ii, 'n_pulls_self'] = (\n",
    "                    machine_state[action]['n_pulls_%i' % agent_ii])\n",
    "                training_data.at[row_ii, 'n_success_self'] = (\n",
    "                    machine_state[action]['n_success_%i' % agent_ii])\n",
    "                training_data.at[row_ii, 'n_pulls_opp'] = (\n",
    "                    machine_state[action]['n_pulls_%i' % (\n",
    "                        (agent_ii + 1) % 2)])\n",
    "                training_data.at[row_ii, 'payout'] = (\n",
    "                    machine_state[action]['payout'] / 100)\n",
    "\n",
    "                # Add row for other agent\n",
    "                row_ii = n_machines + 4 * (round_num - 1) + 2 * agent_ii + 1\n",
    "                other_agent = (agent_ii + 1) % 2\n",
    "                training_data.at[row_ii, 'round_num'] = round_num\n",
    "                training_data.at[row_ii, 'machine_id'] = action\n",
    "                training_data.at[row_ii, 'agent_id'] = other_agent\n",
    "                training_data.at[row_ii, 'n_pulls_self'] = (\n",
    "                    machine_state[action]['n_pulls_%i' % other_agent])\n",
    "                training_data.at[row_ii, 'n_success_self'] = (\n",
    "                    machine_state[action]['n_success_%i' % other_agent])\n",
    "                training_data.at[row_ii, 'n_pulls_opp'] = (\n",
    "                    machine_state[action]['n_pulls_%i' % agent_ii])\n",
    "                training_data.at[row_ii, 'payout'] = (\n",
    "                    machine_state[action]['payout'] / 100)\n",
    "                \n",
    "        else:\n",
    "            # Add initial data for all machines\n",
    "            for action in range(n_machines):\n",
    "                row_ii = action\n",
    "                training_data.at[row_ii, 'round_num'] = round_num\n",
    "                training_data.at[row_ii, 'machine_id'] = action\n",
    "                training_data.at[row_ii, 'agent_id'] = -1\n",
    "                training_data.at[row_ii, 'n_pulls_self'] = 0\n",
    "                training_data.at[row_ii, 'n_success_self'] = 0\n",
    "                training_data.at[row_ii, 'n_pulls_opp'] = 0\n",
    "                training_data.at[row_ii, 'payout'] = (\n",
    "                    machine_state[action]['payout'] / 100)\n",
    "            \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hairy-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8096, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = log_training(game)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "reduced-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7996, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['round_num'] != 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "automated-documentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8096, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-electron",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
